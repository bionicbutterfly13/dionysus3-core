# Feature 003: Semantic Search

**Status**: Planning
**Created**: 2025-12-15
**Author**: Mani Saint-Victor, MD

## Overview

Enable semantic similarity search for memories using vector embeddings stored in Neo4j. This allows intelligent recall based on meaning rather than exact keyword matching.

## Problem Statement

Current memory retrieval relies on exact text matching or simple keyword search. This fails when:
- User asks about "rate limiting" but memory says "throttling requests"
- Concepts are expressed differently across sessions
- Related memories exist but use different terminology

## Solution

Leverage the embeddings already generated by Ollama (nomic-embed-text, 768 dimensions) stored in Neo4j Memory nodes to perform cosine similarity search.

## User Stories

### US1: Basic Semantic Query
**As the** Dionysus system
**I want to** query memories by semantic similarity
**So that** I can recall relevant context even when exact words don't match

**Acceptance Criteria:**
- Query with natural language text
- Return top-k most similar memories
- Include similarity scores in results
- Filter by project_id, session_id, or date range

### US2: MCP Tool for Semantic Recall
**As a** Claude Code session
**I want to** use an MCP tool to semantically search memories
**So that** I can inject relevant context into my responses

**Acceptance Criteria:**
- `semantic_recall` MCP tool available
- Configurable similarity threshold (default 0.7)
- Returns formatted context for injection
- Respects memory importance scores

### US3: Hybrid Search
**As the** Dionysus system
**I want to** combine semantic and keyword search
**So that** I get both exact matches and semantic matches

**Acceptance Criteria:**
- Keyword matches boosted in ranking
- Semantic matches fill gaps
- Configurable blend ratio
- Single unified result set

## Technical Architecture

```
Query Text → Ollama Embedding → Neo4j Vector Index → Ranked Results
                                       ↓
                              Cosine Similarity
                                       ↓
                              Top-K Selection
```

### Components

1. **EmbeddingService** - Generate query embeddings via Ollama
2. **VectorSearchService** - Execute Neo4j vector similarity queries
3. **SemanticRecallTool** - MCP tool wrapper
4. **API Endpoints** - REST API for external access

### Neo4j Vector Index

```cypher
CREATE VECTOR INDEX memory_embedding_index IF NOT EXISTS
FOR (m:Memory) ON (m.embedding)
OPTIONS {
  indexConfig: {
    `vector.dimensions`: 768,
    `vector.similarity_function`: 'cosine'
  }
}
```

### Query Pattern

```cypher
MATCH (m:Memory)
WHERE m.project_id = $project_id
WITH m, vector.similarity.cosine(m.embedding, $query_embedding) AS score
WHERE score >= $threshold
RETURN m.id, m.content, m.memory_type, m.importance, score
ORDER BY score DESC
LIMIT $top_k
```

## API Design

### POST /api/memory/semantic-search

```json
{
  "query": "How do we handle rate limiting?",
  "top_k": 10,
  "threshold": 0.7,
  "filters": {
    "project_id": "dionysus-core",
    "session_id": null,
    "from_date": "2025-12-01T00:00:00Z",
    "to_date": null
  }
}
```

**Response:**
```json
{
  "query": "How do we handle rate limiting?",
  "results": [
    {
      "id": "mem-123",
      "content": "Implemented token bucket algorithm for request throttling",
      "memory_type": "procedural",
      "importance": 0.8,
      "similarity_score": 0.92,
      "session_id": "sess-abc",
      "project_id": "dionysus-core",
      "created_at": "2025-12-10T14:30:00Z"
    }
  ],
  "count": 1,
  "embedding_time_ms": 45,
  "search_time_ms": 12
}
```

## Dependencies

- Feature 002 complete (embeddings stored in Neo4j)
- Neo4j 5.x with vector index support
- Ollama with nomic-embed-text model
- n8n webhook for embedding generation

## Out of Scope

- Embedding fine-tuning
- Multi-modal search (images, audio)
- Real-time embedding updates (handled by sync in 002)
- Cross-user memory search

## Success Metrics

- Query latency < 200ms for 10k memories
- Relevance score > 0.8 for top-3 results on test queries
- Zero additional infrastructure (uses existing Neo4j + Ollama)
